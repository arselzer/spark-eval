{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d98322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import string\n",
    "import pathlib\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from urllib.parse import urlsplit, urlunsplit\n",
    "import requests\n",
    "import json\n",
    "from py4j.protocol import Py4JJavaError, Py4JError\n",
    "import glob\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a04030-0a23-45df-8e70-6a296a4f582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "#SPARK_MEMORY = 900\n",
    "SPARK_MEMORY = 16\n",
    "#SPARK_CORES = 60\n",
    "SPARK_CORES = 8\n",
    "DBHOST = 'postgres'\n",
    "QUERY_TIMEOUT = 60 * 30\n",
    "QUERY_TIMEOUT = 60 * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7397f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"app\") \\\n",
    "        .master(f'local[{SPARK_CORES}]') \\\n",
    "        .config(\"spark.driver.memory\", f'{SPARK_MEMORY}g') \\\n",
    "        .config(\"spark.executor.memory\", f'{SPARK_MEMORY}g') \\\n",
    "        .config(\"spark.memory.offHeap.enabled\",False) \\\n",
    "        .config(\"spark.jars\", \"postgresql-42.3.3.jar\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "## Cluster\n",
    "# def create_spark():\n",
    "#     spark = SparkSession.builder \\\n",
    "#         .appName(\"app\") \\\n",
    "#         .master('spark://10.100.42.35:7078') \\\n",
    "#         .config(\"spark.driver.memory\", f'{SPARK_MEMORY}g') \\\n",
    "#         .config(\"spark.executor.memory\", f'{SPARK_MEMORY}g') \\\n",
    "#         .config(\"spark.driver.host\", \"10.100.42.223\") \\\n",
    "#         .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "#         .config(\"spark.driver.port\", \"4060\") \\\n",
    "#         .config(\"spark.memory.offHeap.enabled\",OFFHEAP) \\\n",
    "#         .config(\"spark.jars\", \"postgresql-42.3.3.jar\") \\\n",
    "#         .getOrCreate()\n",
    "#     return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4170360b-134b-4619-915b-391e877bc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics(spark, group_id):\n",
    "    parsed = list(urlsplit(spark.sparkContext.uiWebUrl))\n",
    "    host_port = parsed[1]\n",
    "    parsed[1] = 'localhost' + host_port[host_port.find(':'):]\n",
    "    API_URL = f'{urlunsplit(parsed)}/api/v1'\n",
    "\n",
    "    app_id = spark.sparkContext.applicationId\n",
    "    sql_queries = requests.get(API_URL + f'/applications/{app_id}/sql', params={'length': '100000'}).json()\n",
    "    query_ids = [q['id'] for q in sql_queries if q['description'] == group_id]\n",
    "    if (len(query_ids) == 0):\n",
    "        print(f'query with group {group_id} not found')\n",
    "        return None\n",
    "    query_id = query_ids[0]\n",
    "    print(f'query id: {query_id}')\n",
    "    \n",
    "    query_details = requests.get(API_URL + f'/applications/{app_id}/sql/{query_id}',\n",
    "                                 params={'details': 'true', 'planDescription': 'true'}).json()\n",
    "    \n",
    "    success_job_ids = query_details['successJobIds']\n",
    "    running_job_ids = query_details['runningJobIds']\n",
    "    failed_job_ids = query_details['failedJobIds']\n",
    "    \n",
    "    job_ids = success_job_ids + running_job_ids + failed_job_ids\n",
    "    \n",
    "    job_details = [requests.get(API_URL + f'/applications/{app_id}/jobs/{jid}').json() for jid in job_ids]\n",
    "    \n",
    "    job_stages = {}\n",
    "    \n",
    "    for j in job_details:\n",
    "        stage_ids = j['stageIds']\n",
    "        \n",
    "        stage_params = {'details': 'true', 'withSummaries': 'true'}\n",
    "        stages = [requests.get(API_URL + f'/applications/{app_id}/stages/{sid}', stage_params) for sid in stage_ids]\n",
    "        \n",
    "        job_stages[j['jobId']] = [stage.json() for stage in stages if stage.status_code == 200] # can be 404\n",
    "    \n",
    "    return query_details, job_details, job_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbbca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_db(spark, dbname):\n",
    "    \n",
    "    username = dbname\n",
    "    password = dbname\n",
    "    dbname = dbname\n",
    "\n",
    "    df_tables = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", f'jdbc:postgresql://{DBHOST}:5432/{dbname}') \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"information_schema.tables\") \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .load()\n",
    "\n",
    "    for idx, row in df_tables.toPandas().iterrows():\n",
    "        if row.table_schema == 'public':\n",
    "            table_name = row.table_name\n",
    "            df = spark.read.format(\"jdbc\") \\\n",
    "                .option(\"url\", f'jdbc:postgresql://{DBHOST}:5432/{dbname}') \\\n",
    "                .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "                .option(\"dbtable\", table_name) \\\n",
    "                .option(\"user\", username) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .load()\n",
    "    \n",
    "            print(table_name)\n",
    "            #print(df.show())\n",
    "            df.createOrReplaceTempView(table_name)\n",
    "\n",
    "def random_str(size=16, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def set_group_id(spark):\n",
    "    group_id = random_str()\n",
    "    spark.sparkContext.setJobGroup(group_id, group_id)\n",
    "    return group_id\n",
    "\n",
    "def cancel_query(spark, seconds, group_id):\n",
    "    time.sleep(seconds)\n",
    "    print(\"cancelling jobs with id \" + group_id)\n",
    "    print(spark.sparkContext.cancelJobGroup(group_id))\n",
    "    print(\"cancelled job\")\n",
    "\n",
    "def cancel_query_after(spark, seconds):\n",
    "    group_id = random_str()\n",
    "    spark.sparkContext.setJobGroup(group_id, group_id)\n",
    "    threading.Thread(target=cancel_query, args=(spark, seconds, group_id,)).start()\n",
    "    return group_id\n",
    "    \n",
    "def run_query(spark, file):\n",
    "    with open(file, 'r') as f:\n",
    "        query = '\\n'.join(filter(lambda line: not line.startswith('limit') and not line.startswith('-'), f.readlines()))\n",
    "        \n",
    "        print(\"running query: \\n\" + query)\n",
    "        return spark.sql(query)\n",
    "\n",
    "def get_resource_usage(t):\n",
    "    return {\n",
    "        'time': t,\n",
    "        'memory': psutil.virtual_memory(),\n",
    "        'cpu': psutil.cpu_percent(interval=None, percpu=True),\n",
    "        'cpu_total': psutil.cpu_percent(interval=None, percpu=False)\n",
    "    }\n",
    "def explain_str(df):\n",
    "    return df._sc._jvm.PythonSQLUtils.explainString(df._jdf.queryExecution(), 'extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead489e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_usage = []\n",
    "\n",
    "def measure_resource_usage(resource_usage):\n",
    "    t = threading.current_thread()\n",
    "    secs = 0\n",
    "    while getattr(t, \"do_run\", True):\n",
    "        resource_usage.append(get_resource_usage(secs))\n",
    "        #print(\"resource usage: \" + str(resource_usage))\n",
    "        secs += 1\n",
    "        time.sleep(1)\n",
    "\n",
    "def benchmark_query(spark, query, respath, run):\n",
    "    spark.sparkContext._jvm.System.gc()\n",
    "    start_time = time.time()\n",
    "\n",
    "    resource_usage = []\n",
    "\n",
    "    measure_thread = threading.Thread(target=measure_resource_usage, args=(resource_usage, ))\n",
    "    measure_thread.start()\n",
    "\n",
    "    group_id = cancel_query_after(spark, QUERY_TIMEOUT)\n",
    "    df1 = run_query(spark, query)\n",
    "    df1.show()\n",
    "\n",
    "    measure_thread.do_run = False\n",
    "\n",
    "    end_time = time.time()\n",
    "    diff_time = end_time - start_time\n",
    "\n",
    "    execution, jobs, job_stages = extract_metrics(spark, group_id)\n",
    "\n",
    "    with open(respath + f'/resource-usage-{run}.json', 'w') as f:\n",
    "        f.write(json.dumps(resource_usage, indent=2))\n",
    "    with open(respath + f'/explain-{run}.txt', 'w') as f:\n",
    "        f.write(explain_str(df1))\n",
    "\n",
    "    resource_list = map(lambda r: [r['time'], r['memory'].used, r['cpu_total']], resource_usage)\n",
    "    resource_df = pd.DataFrame(resource_list, columns = ['time', 'memory_used', 'cpu_used'])\n",
    "    resource_df.to_csv(respath + f'/resource-usage-{run}.csv')\n",
    "\n",
    "    peak_memory = max(map(lambda r: r['memory'].used, resource_usage)) / (1000 * 1000 * 1000) # GB\n",
    "\n",
    "    if execution is not None:\n",
    "            with open(respath + f'/execution-{run}.json', 'w') as f:\n",
    "                f.write(json.dumps(execution, indent=2))\n",
    "            with open(respath + f'/jobs-{run}.json', 'w') as f:\n",
    "                f.write(json.dumps(jobs, indent=2))\n",
    "            with open(respath + f'/stages-{run}.json', 'w') as f:\n",
    "                f.write(json.dumps(job_stages, indent=2))\n",
    "    return (diff_time, peak_memory)\n",
    "\n",
    "def benchmark(spark, dbname, query_file, mode, run):\n",
    "    #spark.sql(\"SET spark.sql.yannakakis.enabled = false\").show()\n",
    "    # run the query once to warm up Spark (load the relation in memory)\n",
    "    #df0 = run_query(query)\n",
    "    #df0.show()\n",
    "    \n",
    "    query_name = os.path.basename(query_file)\n",
    "\n",
    "    respath = f'benchmark-results-{dbname}/' + query_name + \"/\" + mode\n",
    "    pathlib.Path(respath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if mode == \"opt\":\n",
    "        spark.sql(\"SET spark.sql.yannakakis.enabled = true\").show()\n",
    "    elif mode == \"ref\":\n",
    "        spark.sql(\"SET spark.sql.yannakakis.enabled = false\").show()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        (runtime, peak_memory) = benchmark_query(spark, query_file, respath, run)\n",
    "        return [query_name, runtime, peak_memory, mode, run]\n",
    "    except Py4JError as e:\n",
    "        print('timeout or error: ' + str(e))\n",
    "        return [query_name, None, None, mode, run]\n",
    "\n",
    "def benchmark_all(dbname, mode, runs, queries, group_in_leaves=False, physical_cj=False, enable_unguarded=False):\n",
    "    spark = create_spark()\n",
    "    import_db(spark, dbname)\n",
    "\n",
    "    if physical_cj:\n",
    "        spark.sql(\"SET spark.sql.codegen.wholeStage = true\").show()\n",
    "        spark.sql(\"SET spark.sql.yannakakis.physicalCountJoinEnabled = true\").show()\n",
    "    else:\n",
    "        spark.sql(\"SET spark.sql.codegen.wholeStage = true\").show()\n",
    "        spark.sql(\"SET spark.sql.yannakakis.physicalCountJoinEnabled = false\").show()\n",
    "    if group_in_leaves:\n",
    "        spark.sql(\"SET spark.sql.yannakakis.countGroupInLeaves = true\").show()\n",
    "    else:\n",
    "        spark.sql(\"SET spark.sql.yannakakis.countGroupInLeaves = false\").show()\n",
    "    if enable_unguarded:\n",
    "        spark.sql(\"SET spark.sql.yannakakis.unguardedEnabled = true\").show()\n",
    "    else:\n",
    "        spark.sql(\"SET spark.sql.yannakakis.unguardedEnabled = false\").show()\n",
    "\n",
    "    results_df = df = pd.DataFrame([], columns = ['query', 'runtime', 'peak_memory', 'mode', 'run', 'group_leaves', 'physical_cj'])\n",
    "    results_file = f'benchmark-results-{dbname}/results-{mode}.csv'\n",
    "    if (os.path.exists(results_file)):\n",
    "        results_df = pd.read_csv(results_file, index_col=0)\n",
    "\n",
    "    for run in runs:\n",
    "        for q in queries:\n",
    "            results = [benchmark(spark, dbname, q, mode, run) + [group_in_leaves, physical_cj]]\n",
    "            new_df = pd.DataFrame(results, columns = ['query', 'runtime', 'peak_memory', 'mode', 'run', 'group_leaves', 'physical_cj'])\n",
    "            results_df = pd.concat([results_df, new_df], ignore_index=True)\n",
    "            results_df.to_csv(f'benchmark-results-{dbname}/results-{mode}.csv')\n",
    "            print(results_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f27431-b292-4cdf-8470-f0015b40fb86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/19 19:27:50 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table: aka_name\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  person_id                      int                  \n",
      "  name                           string               \n",
      "  imdb_index                     string               \n",
      "  name_pcode_cf                  string               \n",
      "  name_pcode_nf                  string               \n",
      "  surname_pcode                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: aka_title\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  title                          string               \n",
      "  imdb_index                     string               \n",
      "  kind_id                        int                  \n",
      "  production_year                int                  \n",
      "  phonetic_code                  string               \n",
      "  episode_of_id                  int                  \n",
      "  season_nr                      int                  \n",
      "  episode_nr                     int                  \n",
      "  note                           string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: cast_info\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  person_id                      int                  \n",
      "  movie_id                       int                  \n",
      "  person_role_id                 int                  \n",
      "  note                           string               \n",
      "  nr_order                       int                  \n",
      "  role_id                        int                  \n",
      "\n",
      "Table: char_name\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  name                           string               \n",
      "  imdb_index                     string               \n",
      "  imdb_id                        int                  \n",
      "  name_pcode_nf                  string               \n",
      "  surname_pcode                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: comp_cast_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  kind                           string               \n",
      "\n",
      "Table: company_name\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  name                           string               \n",
      "  country_code                   string               \n",
      "  imdb_id                        int                  \n",
      "  name_pcode_nf                  string               \n",
      "  name_pcode_sf                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: company_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  kind                           string               \n",
      "\n",
      "Table: complete_cast\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  subject_id                     int                  \n",
      "  status_id                      int                  \n",
      "\n",
      "Table: info_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  info                           string               \n",
      "\n",
      "Table: keyword\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  keyword                        string               \n",
      "  phonetic_code                  string               \n",
      "\n",
      "Table: kind_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  kind                           string               \n",
      "\n",
      "Table: link_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  link                           string               \n",
      "\n",
      "Table: movie_companies\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  company_id                     int                  \n",
      "  company_type_id                int                  \n",
      "  note                           string               \n",
      "\n",
      "Table: movie_info\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  info_type_id                   int                  \n",
      "  info                           string               \n",
      "  note                           string               \n",
      "\n",
      "Table: movie_keyword\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  keyword_id                     int                  \n",
      "\n",
      "Table: movie_link\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  movie_id                       int                  \n",
      "  linked_movie_id                int                  \n",
      "  link_type_id                   int                  \n",
      "\n",
      "Table: name\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  name                           string               \n",
      "  imdb_index                     string               \n",
      "  imdb_id                        int                  \n",
      "  gender                         string               \n",
      "  name_pcode_cf                  string               \n",
      "  name_pcode_nf                  string               \n",
      "  surname_pcode                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: person_info\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  person_id                      int                  \n",
      "  info_type_id                   int                  \n",
      "  info                           string               \n",
      "  note                           string               \n",
      "\n",
      "Table: role_type\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  role                           string               \n",
      "\n",
      "Table: test1\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  person_id                      int                  \n",
      "  name                           string               \n",
      "  imdb_index                     string               \n",
      "  name_pcode_cf                  string               \n",
      "  name_pcode_nf                  string               \n",
      "  surname_pcode                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: test2\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  person_id                      int                  \n",
      "  name                           string               \n",
      "  imdb_index                     string               \n",
      "  name_pcode_cf                  string               \n",
      "  name_pcode_nf                  string               \n",
      "  surname_pcode                  string               \n",
      "  md5sum                         string               \n",
      "\n",
      "Table: title\n",
      "--------------------------------------------------\n",
      "  id                             int                  \n",
      "  title                          string               \n",
      "  imdb_index                     string               \n",
      "  kind_id                        int                  \n",
      "  production_year                int                  \n",
      "  imdb_id                        int                  \n",
      "  phonetic_code                  string               \n",
      "  episode_of_id                  int                  \n",
      "  season_nr                      int                  \n",
      "  episode_nr                     int                  \n",
      "  series_years                   string               \n",
      "  md5sum                         string               \n"
     ]
    }
   ],
   "source": [
    "spark = create_spark()\n",
    "\n",
    "def show_all_table_columns():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ShowTableColumns\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Get all tables in the database\n",
    "    tables = spark.sql(f\"SHOW TABLES\").collect()\n",
    "\n",
    "    for table_row in tables:\n",
    "        table_name = table_row['tableName']\n",
    "\n",
    "        print(f\"\\nTable: {table_name}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        try:\n",
    "            # Get column information\n",
    "            columns = spark.sql(f\"DESCRIBE TABLE {table_name}\").collect()\n",
    "\n",
    "            for col in columns:\n",
    "                col_name = col['col_name']\n",
    "                data_type = col['data_type']\n",
    "                comment = col['comment'] if col['comment'] else ''\n",
    "                print(f\"  {col_name:<30} {data_type:<20} {comment}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error describing table: {e}\")\n",
    "\n",
    "show_all_table_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a33da7-a411-415b-b065-87ea2830ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-----------+\n",
      "|namespace|      tableName|isTemporary|\n",
      "+---------+---------------+-----------+\n",
      "|         |       aka_name|       true|\n",
      "|         |      aka_title|       true|\n",
      "|         |      cast_info|       true|\n",
      "|         |      char_name|       true|\n",
      "|         | comp_cast_type|       true|\n",
      "|         |   company_name|       true|\n",
      "|         |   company_type|       true|\n",
      "|         |  complete_cast|       true|\n",
      "|         |      info_type|       true|\n",
      "|         |        keyword|       true|\n",
      "|         |      kind_type|       true|\n",
      "|         |      link_type|       true|\n",
      "|         |movie_companies|       true|\n",
      "|         |     movie_info|       true|\n",
      "|         |  movie_keyword|       true|\n",
      "|         |     movie_link|       true|\n",
      "|         |           name|       true|\n",
      "|         |    person_info|       true|\n",
      "|         |      role_type|       true|\n",
      "|         |          title|       true|\n",
      "+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c3837-5334-46f7-9f4e-b01966e8749a",
   "metadata": {},
   "source": [
    "## SNAP Benchmark\n",
    "\n",
    "### Optimized execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8c1d5-2fe0-4853-81ae-56f40f8a8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "group_in_leaves = False\n",
    "dbname = 'snap'\n",
    "mode = 'opt'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "#runs = ['1']\n",
    "####\n",
    "\n",
    "tables = ['patents', 'wiki', 'google', 'dblp']\n",
    "#tables = ['wiki']\n",
    "\n",
    "\n",
    "for tablename in tables:\n",
    "    queries = sorted(glob.glob(f'snap-queries/all/{tablename}-*'))\n",
    "    print('running queries: ' + str(queries))\n",
    "    benchmark_all(dbname, mode, runs, queries, physical_cj=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e5d6e-463b-4fe5-afec-a01bef351ce4",
   "metadata": {},
   "source": [
    "### Ref execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c01dd-4cd3-4cb7-8e44-58f9deb2327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "group_in_leaves = False\n",
    "dbname = 'snap'\n",
    "mode = 'ref'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "####\n",
    "\n",
    "queries = ['snap-queries/all/patents-path02.sql',\n",
    "          'snap-queries/all/patents-path03.sql',\n",
    "          'snap-queries/all/patents-path04.sql',\n",
    "          'snap-queries/all/patents-path05.sql',\n",
    "          'snap-queries/all/patents-tree01.sql',\n",
    "          'snap-queries/all/wiki-path02.sql',\n",
    "           'snap-queries/all/google-path02.sql',\n",
    "           'snap-queries/all/google-path03.sql',\n",
    "           'snap-queries/all/google-path04.sql',\n",
    "           'snap-queries/all/dblp-path02.sql',\n",
    "           'snap-queries/all/dblp-path03.sql',\n",
    "           'snap-queries/all/dblp-path04.sql',\n",
    "           'snap-queries/all/dblp-path05.sql',\n",
    "           'snap-queries/all/dblp-tree01.sql',\n",
    "           'snap-queries/all/dblp-tree02.sql'\n",
    "          ]\n",
    "\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "\n",
    "benchmark_all(dbname, mode, runs, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937d945-3c03-494f-8a5f-8f1f69bf5a22",
   "metadata": {},
   "source": [
    "## LSQB Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7beb471-30e3-41c8-a6ba-4aac25bc4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "dbname = 'lsqb'\n",
    "group_in_leaves = False\n",
    "physical_cj = True\n",
    "#mode = 'opt'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "runs = ['1', '2']\n",
    "####\n",
    "\n",
    "queries = ['lsqb/sql/q1.sql', 'lsqb/sql/q4.sql']\n",
    "queries_hints = ['lsqb/sql/q1-hint.sql', 'lsqb/sql/q4-hint.sql']\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "#benchmark_all(dbname, 'opt', runs, queries, group_in_leaves=False, physical_cj=True)\n",
    "#benchmark_all(dbname, 'opt', runs, queries_hints, group_in_leaves=False, physical_cj=True)\n",
    "\n",
    "#benchmark_all(dbname, 'opt', ['1'], ['lsqb/sql/q4.sql', 'lsqb/sql/q4-hint.sql'], group_in_leaves=False, physical_cj=True)\n",
    "#benchmark_all(dbname, 'opt', ['3', '4', '5', '6'], ['lsqb/sql/q4.sql', 'lsqb/sql/q4-hint.sql'], group_in_leaves=False, physical_cj=True)\n",
    "#benchmark_all(dbname, 'opt', ['1', '2', '3', '4', '5', '6'], ['lsqb/sql/q4.sql', 'lsqb/sql/q4-hint.sql'], group_in_leaves=False, physical_cj=False)\n",
    "\n",
    "#benchmark_all(dbname, 'opt', ['1', '2', '3', '4', '5', '6'], ['lsqb/sql/q1-hint.sql'], group_in_leaves=False, physical_cj=False)\n",
    "#benchmark_all(dbname, 'opt', ['1', '2', '3', '4', '5', '6'], ['lsqb/sql/q1-hint.sql'], group_in_leaves=False, physical_cj=True)\n",
    "#benchmark_all(dbname, 'opt', ['3', '4', '5', '6'], ['lsqb/sql/q1.sql'], group_in_leaves=False, physical_cj=False)\n",
    "#benchmark_all(dbname, 'opt', ['3', '4', '5', '6'], ['lsqb/sql/q1.sql'], group_in_leaves=False, physical_cj=True)\n",
    "benchmark_all(dbname, 'ref', ['4', '5', '6'], ['lsqb/sql/q1.sql'])\n",
    "\n",
    "\n",
    "#benchmark_all(dbname, 'opt', runs, queries_hints, group_in_leaves=False, physical_cj=True)\n",
    "#benchmark_all(dbname, 'ref', ['3', '4', '5', '6'], ['lsqb/sql/q4.sql'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09492e05",
   "metadata": {},
   "source": [
    "## TPC-H Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67544c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "group_in_leaves = False\n",
    "dbname = 'tpch'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "#runs = ['x1', 'x2']\n",
    "####\n",
    "\n",
    "queries = ['tpch-kit/dbgen/queries/postgres/2.sql',\n",
    "           'tpch-kit/dbgen/queries/postgres/11.sql', \n",
    "           'tpch-kit/dbgen/queries/postgres/11-hint.sql']\n",
    "queries += ['tpch-queries/median-1.sql', 'tpch-queries/median-1-hint.sql']\n",
    "\n",
    "#queries = ['tpch-queries/median-1.sql', 'tpch-queries/median-1-hint.sql' ]\n",
    "#queries = ['tpch-kit/dbgen/queries/postgres/11.sql', \n",
    "#           'tpch-kit/dbgen/queries/postgres/11-hint.sql']\n",
    "#queries = ['tpch-queries/2-subq.sql'] #, 'tpch-queries/2-subq-hint.sql']\n",
    "\n",
    "#queries = sorted(glob.glob('tpch-kit/dbgen/queries/*.sql'))\n",
    "\n",
    "queries = ['tpch-kit/dbgen/queries/postgres/18.sql']\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "#benchmark_all(dbname, 'ref', ['x'], queries)\n",
    "benchmark_all(dbname, 'opt', ['x'], queries, group_in_leaves = group_in_leaves, physical_cj=True, enable_unguarded=True)\n",
    "#benchmark_all(dbname, 'ref', ['3', '4', '5', '6'], queries)\n",
    "#benchmark_all(dbname, 'opt', ['3', '4', '5', '6'], queries, group_in_leaves = group_in_leaves, physical_cj=True)\n",
    "#benchmark_all(dbname, 'opt', ['1', '2', '3', '4', '5', '6'], queries, group_in_leaves = group_in_leaves, physical_cj=False)\n",
    "#benchmark_all(dbname, 'opt', runs, queries, group_in_leaves = group_in_leaves, physical_cj=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e18e10-cfa2-4f17-847f-dba980cbd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## JOB (IMDB) Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81adc48a-0108-498f-8a72-6d4c40c6b5c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHOW TABLES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251fb301-811b-49ab-ada6-8f2b5d566031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running queries: ['job/unguarded/10a-unguarded-2.sql', 'job/unguarded/11a-unguarded-2.sql', 'job/unguarded/12a-unguarded-2.sql', 'job/unguarded/13a-unguarded-2.sql', 'job/unguarded/14a-unguarded-2.sql', 'job/unguarded/15a-unguarded-2.sql', 'job/unguarded/16a-unguarded-2.sql', 'job/unguarded/17a-unguarded-2.sql', 'job/unguarded/18a-unguarded-2.sql', 'job/unguarded/19a-unguarded-2.sql', 'job/unguarded/1a-unguarded-2.sql', 'job/unguarded/20a-unguarded-2.sql', 'job/unguarded/22a-unguarded-2.sql', 'job/unguarded/23a-unguarded-2.sql', 'job/unguarded/24a-unguarded-2.sql', 'job/unguarded/25a-unguarded-2.sql', 'job/unguarded/26a-unguarded-2.sql', 'job/unguarded/27a-unguarded-2.sql', 'job/unguarded/28a-unguarded-2.sql', 'job/unguarded/29a-unguarded-2.sql', 'job/unguarded/2a-unguarded-2.sql', 'job/unguarded/30a-unguarded-2.sql', 'job/unguarded/31a-unguarded-2.sql', 'job/unguarded/32a-unguarded-2.sql', 'job/unguarded/33a-unguarded-2.sql', 'job/unguarded/3a-unguarded-2.sql', 'job/unguarded/4a-unguarded-2.sql', 'job/unguarded/5a-unguarded-2.sql', 'job/unguarded/6a-unguarded-2.sql', 'job/unguarded/7a-unguarded-2.sql', 'job/unguarded/8a-unguarded-2.sql', 'job/unguarded/9a-unguarded-2.sql']\n",
      "aka_name\n",
      "aka_title\n",
      "cast_info\n",
      "char_name\n",
      "comp_cast_type\n",
      "company_name\n",
      "company_type\n",
      "complete_cast\n",
      "info_type\n",
      "keyword\n",
      "kind_type\n",
      "link_type\n",
      "movie_companies\n",
      "movie_info\n",
      "movie_keyword\n",
      "movie_link\n",
      "name\n",
      "person_info\n",
      "role_type\n",
      "title\n",
      "test1\n",
      "test2\n",
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.codegen...| true|\n",
      "+--------------------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.yannaka...| true|\n",
      "+--------------------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.yannaka...|false|\n",
      "+--------------------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.yannaka...| true|\n",
      "+--------------------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.yannaka...| true|\n",
      "+--------------------+-----+\n",
      "\n",
      "running query: \n",
      "SELECT MIN(chn.name) AS uncredited_voiced_character,\n",
      "\n",
      "       MIN(t.title) AS russian_movie,\n",
      "\n",
      "       chn.name_pcode_cf,\n",
      "\n",
      "       ct.kind\n",
      "\n",
      "FROM char_name AS chn,\n",
      "\n",
      "     cast_info AS ci,\n",
      "\n",
      "     company_name AS cn,\n",
      "\n",
      "     company_type AS ct,\n",
      "\n",
      "     movie_companies AS mc,\n",
      "\n",
      "     role_type AS rt,\n",
      "\n",
      "     title AS t\n",
      "\n",
      "WHERE ci.note LIKE '%(voice)%'\n",
      "\n",
      "  AND ci.note LIKE '%(uncredited)%'\n",
      "\n",
      "  AND cn.country_code = '[ru]'\n",
      "\n",
      "  AND rt.role = 'actor'\n",
      "\n",
      "  AND t.production_year > 2005\n",
      "\n",
      "  AND t.id = mc.movie_id\n",
      "\n",
      "  AND t.id = ci.movie_id\n",
      "\n",
      "  AND ci.movie_id = mc.movie_id\n",
      "\n",
      "  AND chn.id = ci.person_role_id\n",
      "\n",
      "  AND rt.id = ci.role_id\n",
      "\n",
      "  AND cn.id = mc.company_id\n",
      "\n",
      "  AND ct.id = mc.company_type_id\n",
      "\n",
      "GROUP BY chn.name_pcode_cf, ct.kind;\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `chn`.`name_pcode_cf` cannot be resolved. Did you mean one of the following? [`chn`.`name_pcode_nf`, `cn`.`name_pcode_nf`, `cn`.`name_pcode_sf`, `chn`.`surname_pcode`, `t`.`episode_nr`].; line 5 pos 7;\n'Aggregate ['chn.name_pcode_cf, kind#787], [min(name#755) AS uncredited_voiced_character#1033, min(title#883) AS russian_movie#1034, 'chn.name_pcode_cf, kind#787]\n+- Filter ((((note#744 LIKE %(voice)% AND note#744 LIKE %(uncredited)%) AND (country_code#774 = [ru])) AND (((role#879 = actor) AND (production_year#886 > 2005)) AND (id#882 = movie_id#817))) AND ((((id#882 = movie_id#742) AND (movie_id#742 = movie_id#817)) AND (id#754 = person_role_id#743)) AND (((id#878 = role_id#746) AND (id#772 = company_id#818)) AND (id#786 = company_type_id#819))))\n   +- Join Inner\n      :- Join Inner\n      :  :- Join Inner\n      :  :  :- Join Inner\n      :  :  :  :- Join Inner\n      :  :  :  :  :- Join Inner\n      :  :  :  :  :  :- SubqueryAlias chn\n      :  :  :  :  :  :  +- SubqueryAlias char_name\n      :  :  :  :  :  :     +- View (`char_name`, [id#754,name#755,imdb_index#756,imdb_id#757,name_pcode_nf#758,surname_pcode#759,md5sum#760])\n      :  :  :  :  :  :        +- Relation [id#754,name#755,imdb_index#756,imdb_id#757,name_pcode_nf#758,surname_pcode#759,md5sum#760] JDBCRelation(char_name) [numPartitions=1]\n      :  :  :  :  :  +- SubqueryAlias ci\n      :  :  :  :  :     +- SubqueryAlias cast_info\n      :  :  :  :  :        +- View (`cast_info`, [id#740,person_id#741,movie_id#742,person_role_id#743,note#744,nr_order#745,role_id#746])\n      :  :  :  :  :           +- Relation [id#740,person_id#741,movie_id#742,person_role_id#743,note#744,nr_order#745,role_id#746] JDBCRelation(cast_info) [numPartitions=1]\n      :  :  :  :  +- SubqueryAlias cn\n      :  :  :  :     +- SubqueryAlias company_name\n      :  :  :  :        +- View (`company_name`, [id#772,name#773,country_code#774,imdb_id#775,name_pcode_nf#776,name_pcode_sf#777,md5sum#778])\n      :  :  :  :           +- Relation [id#772,name#773,country_code#774,imdb_id#775,name_pcode_nf#776,name_pcode_sf#777,md5sum#778] JDBCRelation(company_name) [numPartitions=1]\n      :  :  :  +- SubqueryAlias ct\n      :  :  :     +- SubqueryAlias company_type\n      :  :  :        +- View (`company_type`, [id#786,kind#787])\n      :  :  :           +- Relation [id#786,kind#787] JDBCRelation(company_type) [numPartitions=1]\n      :  :  +- SubqueryAlias mc\n      :  :     +- SubqueryAlias movie_companies\n      :  :        +- View (`movie_companies`, [id#816,movie_id#817,company_id#818,company_type_id#819,note#820])\n      :  :           +- Relation [id#816,movie_id#817,company_id#818,company_type_id#819,note#820] JDBCRelation(movie_companies) [numPartitions=1]\n      :  +- SubqueryAlias rt\n      :     +- SubqueryAlias role_type\n      :        +- View (`role_type`, [id#878,role#879])\n      :           +- Relation [id#878,role#879] JDBCRelation(role_type) [numPartitions=1]\n      +- SubqueryAlias t\n         +- SubqueryAlias title\n            +- View (`title`, [id#882,title#883,imdb_index#884,kind_id#885,production_year#886,imdb_id#887,phonetic_code#888,episode_of_id#889,season_nr#890,episode_nr#891,series_years#892,md5sum#893])\n               +- Relation [id#882,title#883,imdb_index#884,kind_id#885,production_year#886,imdb_id#887,phonetic_code#888,episode_of_id#889,season_nr#890,episode_nr#891,series_years#892,md5sum#893] JDBCRelation(title) [numPartitions=1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#queries = ['job/29a-unguarded.sql']\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#queries = ['job/21a-unguarded.sql']\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning queries: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(queries))\n\u001b[0;32m---> 20\u001b[0m \u001b[43mbenchmark_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphysical_cj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_unguarded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#benchmark_all(dbname, 'opt', ['1'], queries, physical_cj=True, enable_unguarded=True)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#benchmark_all(dbname, 'ref', runs, queries)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m benchmark_all(dbname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m], queries)\n",
      "Cell \u001b[0;32mIn[6], line 103\u001b[0m, in \u001b[0;36mbenchmark_all\u001b[0;34m(dbname, mode, runs, queries, group_in_leaves, physical_cj, enable_unguarded)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[0;32m--> 103\u001b[0m         results \u001b[38;5;241m=\u001b[39m [\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m [group_in_leaves, physical_cj]]\n\u001b[1;32m    104\u001b[0m         new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_memory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphysical_cj\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    105\u001b[0m         results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, new_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(spark, dbname, query_file, mode, run)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     (runtime, peak_memory) \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrespath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [query_name, runtime, peak_memory, mode, run]\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mbenchmark_query\u001b[0;34m(spark, query, respath, run)\u001b[0m\n\u001b[1;32m     19\u001b[0m measure_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     21\u001b[0m group_id \u001b[38;5;241m=\u001b[39m cancel_query_after(spark, QUERY_TIMEOUT)\n\u001b[0;32m---> 22\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m df1\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     25\u001b[0m measure_thread\u001b[38;5;241m.\u001b[39mdo_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mrun_query\u001b[0;34m(spark, file)\u001b[0m\n\u001b[1;32m     52\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m line: \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m), f\u001b[38;5;241m.\u001b[39mreadlines()))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning query: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m query)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py:1556\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1554\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1555\u001b[0m         )\n\u001b[0;32m-> 1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `chn`.`name_pcode_cf` cannot be resolved. Did you mean one of the following? [`chn`.`name_pcode_nf`, `cn`.`name_pcode_nf`, `cn`.`name_pcode_sf`, `chn`.`surname_pcode`, `t`.`episode_nr`].; line 5 pos 7;\n'Aggregate ['chn.name_pcode_cf, kind#787], [min(name#755) AS uncredited_voiced_character#1033, min(title#883) AS russian_movie#1034, 'chn.name_pcode_cf, kind#787]\n+- Filter ((((note#744 LIKE %(voice)% AND note#744 LIKE %(uncredited)%) AND (country_code#774 = [ru])) AND (((role#879 = actor) AND (production_year#886 > 2005)) AND (id#882 = movie_id#817))) AND ((((id#882 = movie_id#742) AND (movie_id#742 = movie_id#817)) AND (id#754 = person_role_id#743)) AND (((id#878 = role_id#746) AND (id#772 = company_id#818)) AND (id#786 = company_type_id#819))))\n   +- Join Inner\n      :- Join Inner\n      :  :- Join Inner\n      :  :  :- Join Inner\n      :  :  :  :- Join Inner\n      :  :  :  :  :- Join Inner\n      :  :  :  :  :  :- SubqueryAlias chn\n      :  :  :  :  :  :  +- SubqueryAlias char_name\n      :  :  :  :  :  :     +- View (`char_name`, [id#754,name#755,imdb_index#756,imdb_id#757,name_pcode_nf#758,surname_pcode#759,md5sum#760])\n      :  :  :  :  :  :        +- Relation [id#754,name#755,imdb_index#756,imdb_id#757,name_pcode_nf#758,surname_pcode#759,md5sum#760] JDBCRelation(char_name) [numPartitions=1]\n      :  :  :  :  :  +- SubqueryAlias ci\n      :  :  :  :  :     +- SubqueryAlias cast_info\n      :  :  :  :  :        +- View (`cast_info`, [id#740,person_id#741,movie_id#742,person_role_id#743,note#744,nr_order#745,role_id#746])\n      :  :  :  :  :           +- Relation [id#740,person_id#741,movie_id#742,person_role_id#743,note#744,nr_order#745,role_id#746] JDBCRelation(cast_info) [numPartitions=1]\n      :  :  :  :  +- SubqueryAlias cn\n      :  :  :  :     +- SubqueryAlias company_name\n      :  :  :  :        +- View (`company_name`, [id#772,name#773,country_code#774,imdb_id#775,name_pcode_nf#776,name_pcode_sf#777,md5sum#778])\n      :  :  :  :           +- Relation [id#772,name#773,country_code#774,imdb_id#775,name_pcode_nf#776,name_pcode_sf#777,md5sum#778] JDBCRelation(company_name) [numPartitions=1]\n      :  :  :  +- SubqueryAlias ct\n      :  :  :     +- SubqueryAlias company_type\n      :  :  :        +- View (`company_type`, [id#786,kind#787])\n      :  :  :           +- Relation [id#786,kind#787] JDBCRelation(company_type) [numPartitions=1]\n      :  :  +- SubqueryAlias mc\n      :  :     +- SubqueryAlias movie_companies\n      :  :        +- View (`movie_companies`, [id#816,movie_id#817,company_id#818,company_type_id#819,note#820])\n      :  :           +- Relation [id#816,movie_id#817,company_id#818,company_type_id#819,note#820] JDBCRelation(movie_companies) [numPartitions=1]\n      :  +- SubqueryAlias rt\n      :     +- SubqueryAlias role_type\n      :        +- View (`role_type`, [id#878,role#879])\n      :           +- Relation [id#878,role#879] JDBCRelation(role_type) [numPartitions=1]\n      +- SubqueryAlias t\n         +- SubqueryAlias title\n            +- View (`title`, [id#882,title#883,imdb_index#884,kind_id#885,production_year#886,imdb_id#887,phonetic_code#888,episode_of_id#889,season_nr#890,episode_nr#891,series_years#892,md5sum#893])\n               +- Relation [id#882,title#883,imdb_index#884,kind_id#885,production_year#886,imdb_id#887,phonetic_code#888,episode_of_id#889,season_nr#890,episode_nr#891,series_years#892,md5sum#893] JDBCRelation(title) [numPartitions=1]\n"
     ]
    }
   ],
   "source": [
    "#### benchmark configuration\n",
    "group_in_leaves = False\n",
    "dbname = 'imdb'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "####\n",
    "\n",
    "queries = ['job/2a.sql', 'job/2b.sql', 'job/2c.sql', 'job/2d.sql',\n",
    "           'job/3a.sql', 'job/3b.sql', 'job/3c.sql',\n",
    "           'job/5a.sql', 'job/5b.sql', 'job/5c.sql',\n",
    "           'job/17a.sql', 'job/17b.sql', 'job/17c.sql', 'job/17d.sql', 'job/17e.sql', 'job/17f.sql',\n",
    "           'job/20a.sql', 'job/20b.sql', 'job/20c.sql',\n",
    "          ]\n",
    "\n",
    "queries = sorted(glob.glob('job/unguarded/*-unguarded-2.sql'))\n",
    "\n",
    "#queries = ['job/29a-unguarded.sql']\n",
    "#queries = ['job/21a-unguarded.sql']\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "benchmark_all(dbname, 'opt', [\"1\", \"2\"], queries, physical_cj=True, enable_unguarded=True)\n",
    "#benchmark_all(dbname, 'opt', ['1'], queries, physical_cj=True, enable_unguarded=True)\n",
    "\n",
    "#benchmark_all(dbname, 'ref', runs, queries)\n",
    "benchmark_all(dbname, 'ref', [\"1\", \"2\"], queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1c9eb-9e98-43cd-9cdb-e6910759b78f",
   "metadata": {},
   "source": [
    "## STATS Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc713f-1a8a-473d-ae10-b126963873f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "dbname = 'stats'\n",
    "#mode = 'opt'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "#runs = ['04']\n",
    "#runs = ['01']\n",
    "####\n",
    "\n",
    "queries = sorted(glob.glob('stats-queries/*.sql'))\n",
    "queries_hint = sorted(glob.glob('stats-queries/hints/*.sql'))\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "#benchmark_all(dbname, 'opt', runs, queries, physical_cj=True)\n",
    "benchmark_all(dbname, 'opt', runs, queries_hint, group_in_leaves=True, physical_cj=True)\n",
    "#benchmark_all(dbname, 'ref', runs, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9b0bf-8eb5-44fb-9252-a9386ca5bd8c",
   "metadata": {},
   "source": [
    "## hetionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07366a-130f-43a8-8b8b-4c0a28afde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### benchmark configuration\n",
    "dbname = 'hetio'\n",
    "#mode = 'opt'\n",
    "runs = ['1', '2', '3', '4', '5', '6']\n",
    "#runs = ['04']\n",
    "#runs = ['01']\n",
    "####\n",
    "\n",
    "queries = sorted(glob.glob('hetio/*.sql'))\n",
    "#queries = ['hetio/CtDpSpD.sql']\n",
    "\n",
    "print('running queries: ' + str(queries))\n",
    "#benchmark_all(dbname, 'opt', runs, queries, physical_cj=True)\n",
    "benchmark_all(dbname, 'opt', runs, queries, group_in_leaves=False, physical_cj=True)\n",
    "benchmark_all(dbname, 'opt', runs, queries, group_in_leaves=False, physical_cj=False)\n",
    "benchmark_all(dbname, 'ref', runs, queries)\n",
    "#benchmark_all(dbname, 'ref', runs, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08624383-3a60-402d-9a3d-3d5bd44b9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark()\n",
    "#import_db(spark, 'stats')\n",
    "import_db(spark, 'lsqb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea49cfe-1fa5-41d2-b621-0d9a8b5a3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "spark.sql(\"SET spark.sql.yannakakis.enabled = false\").show()\n",
    "#spark.sql(\"SET spark.sql.yannakakis.enabled = false\").show()\n",
    "#df = run_query(spark, 'stats-queries/142-135.sql')\n",
    "#df = run_query(spark, 'stats-queries/hints/142-135-hint.sql')\n",
    "#df = run_query(spark, 'stats-queries/hints/141-068-hint.sql')\n",
    "df = run_query(spark, 'lsqb/sql/q1.sql')\n",
    "df.show()\n",
    "print(explain_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0861d-f87e-4ab4-8e1d-23d9c6752c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.sql('select count(*) from comments as c')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f47b7f-d053-42cf-b50c-cf78aeefe9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('cache table comments').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b92b6-7d05-49b5-aef0-2313a0d9a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = 'a'\n",
    "a2 = 'a'\n",
    "\n",
    "set([a1, 'b']) - set([a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8668da-83dd-46b6-8901-edd97b0eb8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
